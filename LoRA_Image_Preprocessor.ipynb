{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMx508X1awcjk0CHYRROgmo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prathameshparit/LoRA_Image_Preprocessor/blob/main/LoRA_Image_Preprocessor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Face Censor"
      ],
      "metadata": {
        "id": "GW5Ob0Cj79JQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/prathameshparit/Face_Censor.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PChhxflOHfFK",
        "outputId": "0cfc436e-02d4-49c9-8de4-4c8cbd1b0be2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Face_Censor'...\n",
            "remote: Enumerating objects: 13, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 13 (delta 0), reused 10 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (13/13), 20.55 MiB | 33.62 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Face_Censor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dt1Rb82L4jS",
        "outputId": "50f0673b-cb64-4fb3-8e03-a223b98cf836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Face_Censor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import logging\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "haMs1SxoLVhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Detector:\n",
        "    def __init__(self, model_path, name=\"\"):\n",
        "        self.graph = tf.Graph()\n",
        "        self.model_path = model_path\n",
        "        self.model_name = name\n",
        "        self.sess = tf.compat.v1.Session(graph=self.graph)\n",
        "        with self.graph.as_default():\n",
        "            self.graph_def = tf.compat.v1.GraphDef()\n",
        "            with tf.io.gfile.GFile(model_path, 'rb') as f:\n",
        "                self.graph_def.ParseFromString(f.read())\n",
        "                tf.import_graph_def(self.graph_def, name='')\n",
        "        print(f\"{self.model_name} model is created..\")\n",
        "\n",
        "    def detect_objects(self, img, threshold=0.3):\n",
        "        print(\n",
        "            \"{} : Object detection has started..\".format(self.model_name))\n",
        "\n",
        "        start_time = time.time()\n",
        "        objects = []\n",
        "\n",
        "        # start the session\n",
        "        with tf.compat.v1.Session(graph=self.graph) as sess:\n",
        "\n",
        "            # reshpae input image to give it to the network\n",
        "            rows = img.shape[0]\n",
        "            cols = img.shape[1]\n",
        "            image_np_expanded = np.expand_dims(img, axis=0)\n",
        "\n",
        "            # run the model\n",
        "            (num, scores, boxes,\n",
        "                classes) = self.sess.run(\n",
        "                    [self.sess.graph.get_tensor_by_name('num_detections:0'),\n",
        "                     self.sess.graph.get_tensor_by_name('detection_scores:0'),\n",
        "                     self.sess.graph.get_tensor_by_name('detection_boxes:0'),\n",
        "                     self.sess.graph.get_tensor_by_name('detection_classes:0')],\n",
        "                feed_dict={'image_tensor:0': image_np_expanded})\n",
        "\n",
        "            # parse the results\n",
        "            for i in range(int(num)):\n",
        "                score = float(scores[0, i])\n",
        "                if score > threshold:\n",
        "                    obj = {}\n",
        "                    obj[\"id\"] = int(classes[0, i])\n",
        "                    obj[\"score\"] = score\n",
        "                    bbox = [float(v) for v in boxes[0, i]]\n",
        "                    obj[\"x1\"] = int(bbox[1] * cols)\n",
        "                    obj[\"y1\"] = int(bbox[0] * rows)\n",
        "                    obj[\"x2\"] = int(bbox[3] * cols)\n",
        "                    obj[\"y2\"] = int(bbox[2] * rows)\n",
        "                    objects.append(obj)\n",
        "\n",
        "            print(f\"{self.model_name} : {len(objects)} objects have been found \")\n",
        "        end_time = time.time()\n",
        "        print(\"{} : Elapsed time: {}\".format(\n",
        "            self.model_name, str(end_time - start_time)))\n",
        "\n",
        "        return objects"
      ],
      "metadata": {
        "id": "GDqK7PyPBBma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def overlay_oval_boxes(image, boxes):\n",
        "    for box in boxes:\n",
        "        x1, y1 = box[\"x1\"], box[\"y1\"]\n",
        "        x2, y2 = box[\"x2\"], box[\"y2\"]\n",
        "        center = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
        "        axes = ((x2 - x1) // 2, (y2 - y1) // 2)\n",
        "        overlay = image.copy()\n",
        "        cv2.ellipse(overlay, center, axes, angle=0, startAngle=0, endAngle=360, color=(0, 0, 0), thickness=cv2.FILLED)\n",
        "        image = cv2.addWeighted(overlay, 1, image, 0, 0)\n",
        "    return image\n",
        "\n",
        "def process_images(input_folder, output_folder, detector, threshold):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "            input_image_path = os.path.join(input_folder, filename)\n",
        "            output_image_path = os.path.join(output_folder, filename)\n",
        "\n",
        "            image = cv2.imread(input_image_path)\n",
        "            faces = detector.detect_objects(image, threshold=threshold)\n",
        "            image = overlay_oval_boxes(image, faces)\n",
        "\n",
        "            cv2.imwrite(output_image_path, image)\n",
        "            print(f'Image {filename} processed and saved successfully at {output_image_path}')"
      ],
      "metadata": {
        "id": "TWiqXuIMFsQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    logging.basicConfig(filename='face_censor.log', level=logging.INFO)\n",
        "\n",
        "    input_folder_path = \"train\"\n",
        "    output_folder_path = \"output\"\n",
        "    model_path = \"/content/Face_Censor/models/face.pb\"\n",
        "    threshold = 0.5\n",
        "\n",
        "    detector = Detector(model_path=model_path, name=\"detection\")\n",
        "\n",
        "    try:\n",
        "        # Create the output folder if it doesn't exist\n",
        "        if not os.path.exists(output_folder_path):\n",
        "            os.makedirs(output_folder_path)\n",
        "\n",
        "        process_images(input_folder_path, output_folder_path, detector, threshold)\n",
        "    except Exception as e:\n",
        "        logging.error(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUy1RSxWGQV0",
        "outputId": "a0f27a2c-2aeb-4f8b-c746-511787aa6e40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "detection model is created..\n",
            "detection : Object detection has started..\n",
            "detection : 1 objects have been found \n",
            "detection : Elapsed time: 1.4088878631591797\n",
            "Image s-ku769pnk-mokshi-original-imagk5mfkfg83dpg-removebg-preview.png processed and saved successfully at output/s-ku769pnk-mokshi-original-imagk5mfkfg83dpg-removebg-preview.png\n",
            "detection : Object detection has started..\n",
            "detection : 1 objects have been found \n",
            "detection : Elapsed time: 0.14954185485839844\n",
            "Image s-ku769pnk-mokshi-original-imagk5mfhusterth-removebg-preview.png processed and saved successfully at output/s-ku769pnk-mokshi-original-imagk5mfhusterth-removebg-preview.png\n",
            "detection : Object detection has started..\n",
            "detection : 1 objects have been found \n",
            "detection : Elapsed time: 0.14715862274169922\n",
            "Image s-ku769pnk-mokshi-original-imagk5mfdgnfewzg-removebg-preview.png processed and saved successfully at output/s-ku769pnk-mokshi-original-imagk5mfdgnfewzg-removebg-preview.png\n",
            "detection : Object detection has started..\n",
            "detection : 1 objects have been found \n",
            "detection : Elapsed time: 0.1376938819885254\n",
            "Image s-ku769pnk-mokshi-original-imagk5mfgwg6ehzk-removebg-preview.png processed and saved successfully at output/s-ku769pnk-mokshi-original-imagk5mfgwg6ehzk-removebg-preview.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Background Remover"
      ],
      "metadata": {
        "id": "8QsG9pRLMBJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://huggingface.co/spaces/aryadytm/remove-photo-background/ /content/remove-photo-background\n",
        "!pip install streamlit\n",
        "%cd /content/remove-photo-background"
      ],
      "metadata": {
        "id": "wwdHNGmwM6EU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from src.utils import change_background, matte\n",
        "from src.st_style import apply_prod_style\n",
        "\n",
        "def load_image(image_path):\n",
        "    return Image.open(image_path)\n",
        "\n",
        "def save_image(image, output_path):\n",
        "    image.save(output_path)\n",
        "\n",
        "def remove_background(input_image, output_path, background_color=\"#FFFFFF\", alpha=1.0):\n",
        "    img_matte = matte(input_image)\n",
        "    img_output = change_background(input_image, img_matte, background_alpha=alpha, background_hex=background_color)\n",
        "    save_image(img_output, output_path)\n",
        "    return img_output\n",
        "\n",
        "def process_image_pipeline(input_image_path, output_folder, background_color=\"#FFFFFF\", alpha=1.0):\n",
        "    # Step 1: Load the input image\n",
        "    input_image = load_image(input_image_path)\n",
        "\n",
        "    # Step 2: Remove background\n",
        "    removed_bg_image = remove_background(input_image, os.path.join(output_folder, \"removed_bg_image.png\"), background_color, alpha)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_image_path = \"/content/WhatsApp Image 2023-11-24 at 23.07.45_ccdea316.jpg\"\n",
        "    output_folder_path = \"/content/output\"\n",
        "    background_color = \"#FFFFFF\"\n",
        "    alpha = 1.0\n",
        "\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder_path):\n",
        "        os.makedirs(output_folder_path)\n",
        "\n",
        "    process_image_pipeline(input_image_path, output_folder_path, background_color, alpha)\n"
      ],
      "metadata": {
        "id": "guPddPwLNdgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2gflfYgNOTlW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}